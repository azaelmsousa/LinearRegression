{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import sys\n",
    "sys.path\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "from diamonds import experiments, normal_equation\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "scoring = {\n",
    "    \t'Negative MSE': 'neg_mean_squared_error',\n",
    "    \t'Negative MAE': 'neg_mean_absolute_error',\n",
    "    \t'R2': 'r2'\n",
    "\t}\n",
    "\n",
    "syntect_features = ['volume', 'ratio_xy', 'ratio_xz']\n",
    "val_size = .15\n",
    "params = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discution 1\n",
    "  - Using the SKlearn SGDregressor with basic params we are now comparing the results.\n",
    "  - Kept only the best results from the first experiment to run the GridSearch for the parameters\n",
    "  - The Log(Y) kept the algorithm more robust reducing the errors mean value\n",
    "  - The Scale kept the algorithm more robust reducing the errors mean value\n",
    "  - The syntetic features wherever they appeards reduces the standard deviation from the MAE/MSE and RSME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "       loss='squared_loss', max_iter=None, n_iter=None, penalty=None,\n",
       "       power_t=0.25, random_state=None, shuffle=True, tol=None,\n",
       "       verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = experiments.get_sklearn_sgd(params)\n",
    "regr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding syntect features ['volume', 'ratio_xy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = experiments.load_train_data()\n",
    "folds, (X_train, X_test, y_train, y_test) = experiments.gen_splits(X, scale=True, \n",
    "                                                             exclude_features=['ratio_xz'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 0\n",
      "Evaluating 1\n",
      "Evaluating 2\n",
      "Evaluating 3\n",
      "Evaluating 4\n",
      "RMSE: \t 1609.3210 +/- 97.7450\n",
      "MSE:  \t 2599468.0829 +/- 319313.5273\n",
      "MAE:  \t 714.2778 +/- 27.7334\n",
      "R2:   \t 0.8172 +/- 0.0210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "experiments.kfold_evaluate(regr, folds, scoring, log_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding syntect features ['volume', 'ratio_xz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = experiments.load_train_data()\n",
    "folds, (X_train, X_test, y_train, y_test) = experiments.gen_splits(X, scale=True, \n",
    "                                                             exclude_features=['ratio_xy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 0\n",
      "Evaluating 1\n",
      "Evaluating 2\n",
      "Evaluating 3\n",
      "Evaluating 4\n",
      "RMSE: \t 1633.7756 +/- 91.1391\n",
      "MSE:  \t 2677528.9644 +/- 302051.6732\n",
      "MAE:  \t 718.6580 +/- 28.2871\n",
      "R2:   \t 0.8117 +/- 0.0197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "experiments.kfold_evaluate(regr, folds, scoring, log_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding syntect features ['volume', 'ratio_xy', 'ratio_xz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = experiments.load_train_data()\n",
    "folds, (X_train, X_test, y_train, y_test) = experiments.gen_splits(X, scale=True, \n",
    "                                                             exclude_features=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 0\n",
      "Evaluating 1\n",
      "Evaluating 2\n",
      "Evaluating 3\n",
      "Evaluating 4\n",
      "RMSE: \t 1541.6432 +/- 91.7475\n",
      "MSE:  \t 2385081.3106 +/- 277095.3156\n",
      "MAE:  \t 697.8126 +/- 20.5680\n",
      "R2:   \t 0.8321 +/- 0.0192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "experiments.kfold_evaluate(regr, folds, scoring, log_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discution 2\n",
    "  - The results doesn't appear to have an statistical difference between then, since the mean and std deviation are practically the same. Although the result with features included has a better R2. \n",
    "  - The SGD goes almost to the same minimal as the normal equation results.\n",
    "  - Whe are now running the GridSearch CV for the SGD to look for better parameters and will be using the last dataset above. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 135 out of 135 | elapsed:  5.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "       loss='squared_loss', max_iter=None, n_iter=None, penalty=None,\n",
       "       power_t=0.25, random_state=None, shuffle=True, tol=None,\n",
       "       verbose=False, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_iter': [5000], 'eta0': [0.1, 0.05, 0.01], 'loss': ['squared_loss'], 'penalty': ['l2', 'l1', None], 'learning_rate': ['invscaling', 'optimal', 'constant']},\n",
       "       pre_dispatch='2*n_jobs', refit='R2', return_train_score='warn',\n",
       "       scoring={'-MSE': 'neg_mean_squared_error', '-MAE': 'neg_mean_absolute_error', 'R2': 'r2'},\n",
       "       verbose=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'learning_rate':['invscaling', 'optimal', 'constant'],\n",
    "    'eta0': [0.1, 0.05, 0.01], # since 0.01 had a good result in the previous results \n",
    "    'penalty': ['l2', 'l1', None], # Those penalties are easier to implement if needed\n",
    "    'loss': ['squared_loss'], # Since we are running the MSE loss function for the Custom Implementing\n",
    "    'max_iter':[5000] # Fixed the number of iterations to avoid the long time executions\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "        '-MSE': 'neg_mean_squared_error',\n",
    "        '-MAE': 'neg_mean_absolute_error',\n",
    "        'R2': 'r2'\n",
    "    }\n",
    "\n",
    "# We are using R2 to refit because it gave a better view of the results above when compared with the MSE and MAE\n",
    "regr = GridSearchCV(regr, params, cv=5, scoring=scoring, refit='R2', n_jobs=-1, verbose=True)\n",
    "regr.fit(X_train, np.log(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.1,\n",
       "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "       loss='squared_loss', max_iter=5000, n_iter=None, penalty=None,\n",
       "       power_t=0.25, random_state=None, shuffle=True, tol=None,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eta0': 0.1,\n",
       " 'learning_rate': 'invscaling',\n",
       " 'loss': 'squared_loss',\n",
       " 'max_iter': 5000,\n",
       " 'penalty': None}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['std_train_-MAE', 'split1_train_-MSE', 'std_fit_time', 'split2_train_-MSE', 'mean_train_-MAE', 'split0_train_R2', 'mean_test_R2', 'split3_test_R2', 'split0_train_-MSE', 'mean_train_R2', 'std_train_-MSE', 'split4_train_-MAE', 'param_learning_rate', 'split2_test_-MSE', 'rank_test_-MSE', 'mean_fit_time', 'split2_test_-MAE', 'split1_test_-MSE', 'std_train_R2', 'split1_train_-MAE', 'split2_train_-MAE', 'std_test_R2', 'split3_test_-MSE', 'split1_test_-MAE', 'rank_test_-MAE', 'std_test_-MSE', 'split3_train_R2', 'split3_train_-MSE', 'split4_test_-MAE', 'param_max_iter', 'split4_test_-MSE', 'std_test_-MAE', 'param_loss', 'split4_train_-MSE', 'params', 'split0_test_-MSE', 'split4_test_R2', 'rank_test_R2', 'mean_test_-MSE', 'split0_test_R2', 'split2_train_R2', 'param_eta0', 'mean_train_-MSE', 'mean_score_time', 'split3_train_-MAE', 'split0_test_-MAE', 'split4_train_R2', 'split3_test_-MAE', 'std_score_time', 'split0_train_-MAE', 'param_penalty', 'mean_test_-MAE', 'split1_test_R2', 'split2_test_R2', 'split1_train_R2'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_eta0</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>rank_test_-MSE</th>\n",
       "      <th>rank_test_-MAE</th>\n",
       "      <th>std_test_-MSE</th>\n",
       "      <th>std_test_-MAE</th>\n",
       "      <th>std_test_R2</th>\n",
       "      <th>mean_test_-MSE</th>\n",
       "      <th>mean_test_-MAE</th>\n",
       "      <th>mean_test_R2</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_R2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>5000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>-0.013529</td>\n",
       "      <td>-0.091500</td>\n",
       "      <td>0.986100</td>\n",
       "      <td>21.696494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>constant</td>\n",
       "      <td>5000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.001516</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>-0.013669</td>\n",
       "      <td>-0.092389</td>\n",
       "      <td>0.985956</td>\n",
       "      <td>10.615460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>5000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>-0.013952</td>\n",
       "      <td>-0.092925</td>\n",
       "      <td>0.985665</td>\n",
       "      <td>20.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>5000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>-0.015003</td>\n",
       "      <td>-0.096400</td>\n",
       "      <td>0.984586</td>\n",
       "      <td>20.512749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>5000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.05</td>\n",
       "      <td>l1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>-0.015028</td>\n",
       "      <td>-0.096519</td>\n",
       "      <td>0.984560</td>\n",
       "      <td>26.909482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>5000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.001322</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>-0.015047</td>\n",
       "      <td>-0.096410</td>\n",
       "      <td>0.984540</td>\n",
       "      <td>28.861118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>5000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.05</td>\n",
       "      <td>l2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>-0.015105</td>\n",
       "      <td>-0.096752</td>\n",
       "      <td>0.984481</td>\n",
       "      <td>21.109486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>5000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>-0.015122</td>\n",
       "      <td>-0.096711</td>\n",
       "      <td>0.984464</td>\n",
       "      <td>21.883833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>5000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l1</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>-0.015194</td>\n",
       "      <td>-0.097098</td>\n",
       "      <td>0.984389</td>\n",
       "      <td>26.829921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>5000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>-0.015237</td>\n",
       "      <td>-0.097252</td>\n",
       "      <td>0.984345</td>\n",
       "      <td>20.958378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             param_learning_rate param_max_iter    param_loss param_eta0  \\\n",
       "rank_test_R2                                                               \n",
       "1                     invscaling           5000  squared_loss        0.1   \n",
       "2                       constant           5000  squared_loss       0.01   \n",
       "3                     invscaling           5000  squared_loss       0.05   \n",
       "4                     invscaling           5000  squared_loss       0.01   \n",
       "5                     invscaling           5000  squared_loss       0.05   \n",
       "6                     invscaling           5000  squared_loss        0.1   \n",
       "7                     invscaling           5000  squared_loss       0.05   \n",
       "8                     invscaling           5000  squared_loss        0.1   \n",
       "9                     invscaling           5000  squared_loss       0.01   \n",
       "10                    invscaling           5000  squared_loss       0.01   \n",
       "\n",
       "             param_penalty  rank_test_-MSE  rank_test_-MAE  std_test_-MSE  \\\n",
       "rank_test_R2                                                                \n",
       "1                     None               1               1       0.000506   \n",
       "2                     None               2               2       0.000467   \n",
       "3                     None               3               3       0.000504   \n",
       "4                     None               4               4       0.000534   \n",
       "5                       l1               5               6       0.000503   \n",
       "6                       l1               6               5       0.000487   \n",
       "7                       l2               7               8       0.000511   \n",
       "8                       l2               8               7       0.000494   \n",
       "9                       l1               9               9       0.000519   \n",
       "10                      l2              10              10       0.000520   \n",
       "\n",
       "              std_test_-MAE  std_test_R2  mean_test_-MSE  mean_test_-MAE  \\\n",
       "rank_test_R2                                                               \n",
       "1                  0.001492     0.000575       -0.013529       -0.091500   \n",
       "2                  0.001516     0.000532       -0.013669       -0.092389   \n",
       "3                  0.001400     0.000573       -0.013952       -0.092925   \n",
       "4                  0.001483     0.000609       -0.015003       -0.096400   \n",
       "5                  0.001425     0.000581       -0.015028       -0.096519   \n",
       "6                  0.001322     0.000559       -0.015047       -0.096410   \n",
       "7                  0.001443     0.000586       -0.015105       -0.096752   \n",
       "8                  0.001396     0.000561       -0.015122       -0.096711   \n",
       "9                  0.001487     0.000596       -0.015194       -0.097098   \n",
       "10                 0.001477     0.000597       -0.015237       -0.097252   \n",
       "\n",
       "              mean_test_R2  mean_fit_time  \n",
       "rank_test_R2                               \n",
       "1                 0.986100      21.696494  \n",
       "2                 0.985956      10.615460  \n",
       "3                 0.985665      20.377451  \n",
       "4                 0.984586      20.512749  \n",
       "5                 0.984560      26.909482  \n",
       "6                 0.984540      28.861118  \n",
       "7                 0.984481      21.109486  \n",
       "8                 0.984464      21.883833  \n",
       "9                 0.984389      26.829921  \n",
       "10                0.984345      20.958378  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "\n",
    "columns = [\n",
    "'param_learning_rate',\n",
    "'param_max_iter',\n",
    "'param_loss',\n",
    "'param_eta0',\n",
    "'param_penalty',\n",
    "'rank_test_-MSE',\n",
    "'rank_test_-MAE',\n",
    "'rank_test_R2',\n",
    "'std_test_-MSE',\n",
    "'std_test_-MAE',\n",
    "'std_test_R2',\n",
    "'mean_test_-MSE',\n",
    "'mean_test_-MAE',\n",
    "'mean_test_R2', \n",
    "'mean_fit_time']\n",
    "\n",
    "results = pd.DataFrame(regr.cv_results_)\n",
    "top10 = results[columns].sort_values(by=['rank_test_R2', 'mean_test_R2']).head(10).copy()\n",
    "top10.sort_values(by=['rank_test_R2', 'mean_test_R2'])\n",
    "top10.set_index('rank_test_R2', inplace=True, drop=True)\n",
    "top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2f2ffd9a20>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "top10.mean_fit_time.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2f2ff5aa58>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,5))\n",
    "top10.mean_test_R2.plot.bar(yerr=top10.std_test_R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2f2feb3198>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "top10.std_test_R2.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_eta0</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>rank_test_-MSE</th>\n",
       "      <th>rank_test_-MAE</th>\n",
       "      <th>std_test_-MSE</th>\n",
       "      <th>std_test_-MAE</th>\n",
       "      <th>std_test_R2</th>\n",
       "      <th>mean_test_-MSE</th>\n",
       "      <th>mean_test_-MAE</th>\n",
       "      <th>mean_test_R2</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_R2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>5000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>-0.013529</td>\n",
       "      <td>-0.091500</td>\n",
       "      <td>0.986100</td>\n",
       "      <td>21.696494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>constant</td>\n",
       "      <td>5000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.001516</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>-0.013669</td>\n",
       "      <td>-0.092389</td>\n",
       "      <td>0.985956</td>\n",
       "      <td>10.615460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>5000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>-0.013952</td>\n",
       "      <td>-0.092925</td>\n",
       "      <td>0.985665</td>\n",
       "      <td>20.377451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>5000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>-0.015003</td>\n",
       "      <td>-0.096400</td>\n",
       "      <td>0.984586</td>\n",
       "      <td>20.512749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>5000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.05</td>\n",
       "      <td>l1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>-0.015028</td>\n",
       "      <td>-0.096519</td>\n",
       "      <td>0.984560</td>\n",
       "      <td>26.909482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>5000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.001322</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>-0.015047</td>\n",
       "      <td>-0.096410</td>\n",
       "      <td>0.984540</td>\n",
       "      <td>28.861118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>5000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.05</td>\n",
       "      <td>l2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>-0.015105</td>\n",
       "      <td>-0.096752</td>\n",
       "      <td>0.984481</td>\n",
       "      <td>21.109486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>5000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>-0.015122</td>\n",
       "      <td>-0.096711</td>\n",
       "      <td>0.984464</td>\n",
       "      <td>21.883833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>5000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l1</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>-0.015194</td>\n",
       "      <td>-0.097098</td>\n",
       "      <td>0.984389</td>\n",
       "      <td>26.829921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>5000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>-0.015237</td>\n",
       "      <td>-0.097252</td>\n",
       "      <td>0.984345</td>\n",
       "      <td>20.958378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             param_learning_rate param_max_iter    param_loss param_eta0  \\\n",
       "rank_test_R2                                                               \n",
       "1                     invscaling           5000  squared_loss        0.1   \n",
       "2                       constant           5000  squared_loss       0.01   \n",
       "3                     invscaling           5000  squared_loss       0.05   \n",
       "4                     invscaling           5000  squared_loss       0.01   \n",
       "5                     invscaling           5000  squared_loss       0.05   \n",
       "6                     invscaling           5000  squared_loss        0.1   \n",
       "7                     invscaling           5000  squared_loss       0.05   \n",
       "8                     invscaling           5000  squared_loss        0.1   \n",
       "9                     invscaling           5000  squared_loss       0.01   \n",
       "10                    invscaling           5000  squared_loss       0.01   \n",
       "\n",
       "             param_penalty  rank_test_-MSE  rank_test_-MAE  std_test_-MSE  \\\n",
       "rank_test_R2                                                                \n",
       "1                     None               1               1       0.000506   \n",
       "2                     None               2               2       0.000467   \n",
       "3                     None               3               3       0.000504   \n",
       "4                     None               4               4       0.000534   \n",
       "5                       l1               5               6       0.000503   \n",
       "6                       l1               6               5       0.000487   \n",
       "7                       l2               7               8       0.000511   \n",
       "8                       l2               8               7       0.000494   \n",
       "9                       l1               9               9       0.000519   \n",
       "10                      l2              10              10       0.000520   \n",
       "\n",
       "              std_test_-MAE  std_test_R2  mean_test_-MSE  mean_test_-MAE  \\\n",
       "rank_test_R2                                                               \n",
       "1                  0.001492     0.000575       -0.013529       -0.091500   \n",
       "2                  0.001516     0.000532       -0.013669       -0.092389   \n",
       "3                  0.001400     0.000573       -0.013952       -0.092925   \n",
       "4                  0.001483     0.000609       -0.015003       -0.096400   \n",
       "5                  0.001425     0.000581       -0.015028       -0.096519   \n",
       "6                  0.001322     0.000559       -0.015047       -0.096410   \n",
       "7                  0.001443     0.000586       -0.015105       -0.096752   \n",
       "8                  0.001396     0.000561       -0.015122       -0.096711   \n",
       "9                  0.001487     0.000596       -0.015194       -0.097098   \n",
       "10                 0.001477     0.000597       -0.015237       -0.097252   \n",
       "\n",
       "              mean_test_R2  mean_fit_time  \n",
       "rank_test_R2                               \n",
       "1                 0.986100      21.696494  \n",
       "2                 0.985956      10.615460  \n",
       "3                 0.985665      20.377451  \n",
       "4                 0.984586      20.512749  \n",
       "5                 0.984560      26.909482  \n",
       "6                 0.984540      28.861118  \n",
       "7                 0.984481      21.109486  \n",
       "8                 0.984464      21.883833  \n",
       "9                 0.984389      26.829921  \n",
       "10                0.984345      20.958378  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refining the search\n",
    "   - Given the above rank we are selecting the 3 top configurations and re-running the grid with more iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 20.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "       loss='squared_loss', max_iter=None, n_iter=None, penalty=None,\n",
       "       power_t=0.25, random_state=None, shuffle=True, tol=None,\n",
       "       verbose=False, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_iter': [100000], 'eta0': [0.1, 0.05, 0.01], 'loss': ['squared_loss'], 'penalty': [None], 'learning_rate': ['invscaling', 'constant']},\n",
       "       pre_dispatch='2*n_jobs', refit='R2', return_train_score='warn',\n",
       "       scoring={'-MSE': 'neg_mean_squared_error', '-MAE': 'neg_mean_absolute_error', 'R2': 'r2'},\n",
       "       verbose=True)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {}\n",
    "regr = experiments.get_sklearn_sgd(params)\n",
    "regr.verbose = False\n",
    "params = {\n",
    "    'learning_rate':['invscaling','constant'],\n",
    "    'eta0': [0.1, 0.05, 0.01], # since 0.01 had a good result in the previous results \n",
    "    'penalty': [None], # Those penalties are easier to implement if needed\n",
    "    'loss': ['squared_loss'], # Since we are running the MSE loss function for the Custom Implementing\n",
    "    'max_iter':[100000] # Fixed the number of iterations to avoid the long time executions\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "        '-MSE': 'neg_mean_squared_error',\n",
    "        '-MAE': 'neg_mean_absolute_error',\n",
    "        'R2': 'r2'\n",
    "    }\n",
    "\n",
    "# We are using R2 to refit because it gave a better view of the results above when compared with the MSE and MAE\n",
    "regr = GridSearchCV(regr, params, cv=5, scoring=scoring, refit='R2', n_jobs=-1, verbose=True)\n",
    "regr.fit(X_train, np.log(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_eta0</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>rank_test_-MSE</th>\n",
       "      <th>rank_test_-MAE</th>\n",
       "      <th>std_test_-MSE</th>\n",
       "      <th>std_test_-MAE</th>\n",
       "      <th>std_test_R2</th>\n",
       "      <th>mean_test_-MSE</th>\n",
       "      <th>mean_test_-MAE</th>\n",
       "      <th>mean_test_R2</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_R2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>100000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>-0.013347</td>\n",
       "      <td>-0.091028</td>\n",
       "      <td>0.986287</td>\n",
       "      <td>409.800223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>100000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>-0.013370</td>\n",
       "      <td>-0.090977</td>\n",
       "      <td>0.986263</td>\n",
       "      <td>409.906274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>100000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>-0.013534</td>\n",
       "      <td>-0.091610</td>\n",
       "      <td>0.986095</td>\n",
       "      <td>384.698237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>constant</td>\n",
       "      <td>100000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>-0.013875</td>\n",
       "      <td>-0.092863</td>\n",
       "      <td>0.985746</td>\n",
       "      <td>201.032899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>constant</td>\n",
       "      <td>100000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.003820</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>-0.015644</td>\n",
       "      <td>-0.100297</td>\n",
       "      <td>0.983934</td>\n",
       "      <td>245.464295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>constant</td>\n",
       "      <td>100000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>0.006954</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>-0.019607</td>\n",
       "      <td>-0.110386</td>\n",
       "      <td>0.979860</td>\n",
       "      <td>246.552158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             param_learning_rate param_max_iter    param_loss param_eta0  \\\n",
       "rank_test_R2                                                               \n",
       "1                     invscaling         100000  squared_loss       0.05   \n",
       "2                     invscaling         100000  squared_loss        0.1   \n",
       "3                     invscaling         100000  squared_loss       0.01   \n",
       "4                       constant         100000  squared_loss       0.01   \n",
       "5                       constant         100000  squared_loss       0.05   \n",
       "6                       constant         100000  squared_loss        0.1   \n",
       "\n",
       "             param_penalty  rank_test_-MSE  rank_test_-MAE  std_test_-MSE  \\\n",
       "rank_test_R2                                                                \n",
       "1                     None               1               2       0.000486   \n",
       "2                     None               2               1       0.000498   \n",
       "3                     None               3               3       0.000495   \n",
       "4                     None               4               4       0.000426   \n",
       "5                     None               5               5       0.001080   \n",
       "6                     None               6               6       0.002519   \n",
       "\n",
       "              std_test_-MAE  std_test_R2  mean_test_-MSE  mean_test_-MAE  \\\n",
       "rank_test_R2                                                               \n",
       "1                  0.001478     0.000552       -0.013347       -0.091028   \n",
       "2                  0.001501     0.000566       -0.013370       -0.090977   \n",
       "3                  0.001430     0.000562       -0.013534       -0.091610   \n",
       "4                  0.000921     0.000461       -0.013875       -0.092863   \n",
       "5                  0.003820     0.001057       -0.015644       -0.100297   \n",
       "6                  0.006954     0.002564       -0.019607       -0.110386   \n",
       "\n",
       "              mean_test_R2  mean_fit_time  \n",
       "rank_test_R2                               \n",
       "1                 0.986287     409.800223  \n",
       "2                 0.986263     409.906274  \n",
       "3                 0.986095     384.698237  \n",
       "4                 0.985746     201.032899  \n",
       "5                 0.983934     245.464295  \n",
       "6                 0.979860     246.552158  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "\n",
    "columns = [\n",
    "'param_learning_rate',\n",
    "'param_max_iter',\n",
    "'param_loss',\n",
    "'param_eta0',\n",
    "'param_penalty',\n",
    "'rank_test_-MSE',\n",
    "'rank_test_-MAE',\n",
    "'rank_test_R2',\n",
    "'std_test_-MSE',\n",
    "'std_test_-MAE',\n",
    "'std_test_R2',\n",
    "'mean_test_-MSE',\n",
    "'mean_test_-MAE',\n",
    "'mean_test_R2', \n",
    "'mean_fit_time']\n",
    "\n",
    "results = pd.DataFrame(regr.cv_results_)\n",
    "top10 = results[columns].sort_values(by=['rank_test_R2', 'mean_test_R2']).head(10).copy()\n",
    "top10.sort_values(by=['rank_test_R2', 'mean_test_R2'])\n",
    "top10.set_index('rank_test_R2', inplace=True, drop=True)\n",
    "top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2f3f00cef0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "top10.mean_fit_time.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2f418c2780>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,5))\n",
    "top10.mean_test_R2.plot.bar(yerr=top10.std_test_R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2f418d7a90>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "top10.std_test_R2.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_eta0</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>rank_test_-MSE</th>\n",
       "      <th>rank_test_-MAE</th>\n",
       "      <th>std_test_-MSE</th>\n",
       "      <th>std_test_-MAE</th>\n",
       "      <th>std_test_R2</th>\n",
       "      <th>mean_test_-MSE</th>\n",
       "      <th>mean_test_-MAE</th>\n",
       "      <th>mean_test_R2</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_R2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>100000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>-0.013347</td>\n",
       "      <td>-0.091028</td>\n",
       "      <td>0.986287</td>\n",
       "      <td>409.800223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>100000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>-0.013370</td>\n",
       "      <td>-0.090977</td>\n",
       "      <td>0.986263</td>\n",
       "      <td>409.906274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>100000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>-0.013534</td>\n",
       "      <td>-0.091610</td>\n",
       "      <td>0.986095</td>\n",
       "      <td>384.698237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>constant</td>\n",
       "      <td>100000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>-0.013875</td>\n",
       "      <td>-0.092863</td>\n",
       "      <td>0.985746</td>\n",
       "      <td>201.032899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>constant</td>\n",
       "      <td>100000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.003820</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>-0.015644</td>\n",
       "      <td>-0.100297</td>\n",
       "      <td>0.983934</td>\n",
       "      <td>245.464295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>constant</td>\n",
       "      <td>100000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>0.006954</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>-0.019607</td>\n",
       "      <td>-0.110386</td>\n",
       "      <td>0.979860</td>\n",
       "      <td>246.552158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             param_learning_rate param_max_iter    param_loss param_eta0  \\\n",
       "rank_test_R2                                                               \n",
       "1                     invscaling         100000  squared_loss       0.05   \n",
       "2                     invscaling         100000  squared_loss        0.1   \n",
       "3                     invscaling         100000  squared_loss       0.01   \n",
       "4                       constant         100000  squared_loss       0.01   \n",
       "5                       constant         100000  squared_loss       0.05   \n",
       "6                       constant         100000  squared_loss        0.1   \n",
       "\n",
       "             param_penalty  rank_test_-MSE  rank_test_-MAE  std_test_-MSE  \\\n",
       "rank_test_R2                                                                \n",
       "1                     None               1               2       0.000486   \n",
       "2                     None               2               1       0.000498   \n",
       "3                     None               3               3       0.000495   \n",
       "4                     None               4               4       0.000426   \n",
       "5                     None               5               5       0.001080   \n",
       "6                     None               6               6       0.002519   \n",
       "\n",
       "              std_test_-MAE  std_test_R2  mean_test_-MSE  mean_test_-MAE  \\\n",
       "rank_test_R2                                                               \n",
       "1                  0.001478     0.000552       -0.013347       -0.091028   \n",
       "2                  0.001501     0.000566       -0.013370       -0.090977   \n",
       "3                  0.001430     0.000562       -0.013534       -0.091610   \n",
       "4                  0.000921     0.000461       -0.013875       -0.092863   \n",
       "5                  0.003820     0.001057       -0.015644       -0.100297   \n",
       "6                  0.006954     0.002564       -0.019607       -0.110386   \n",
       "\n",
       "              mean_test_R2  mean_fit_time  \n",
       "rank_test_R2                               \n",
       "1                 0.986287     409.800223  \n",
       "2                 0.986263     409.906274  \n",
       "3                 0.986095     384.698237  \n",
       "4                 0.985746     201.032899  \n",
       "5                 0.983934     245.464295  \n",
       "6                 0.979860     246.552158  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10.sort_values(['rank_test_R2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_eta0</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>rank_test_-MSE</th>\n",
       "      <th>rank_test_-MAE</th>\n",
       "      <th>std_test_-MSE</th>\n",
       "      <th>std_test_-MAE</th>\n",
       "      <th>std_test_R2</th>\n",
       "      <th>mean_test_-MSE</th>\n",
       "      <th>mean_test_-MAE</th>\n",
       "      <th>mean_test_R2</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_R2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>100000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>-0.013370</td>\n",
       "      <td>-0.090977</td>\n",
       "      <td>0.986263</td>\n",
       "      <td>409.906274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>100000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>-0.013347</td>\n",
       "      <td>-0.091028</td>\n",
       "      <td>0.986287</td>\n",
       "      <td>409.800223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>100000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>-0.013534</td>\n",
       "      <td>-0.091610</td>\n",
       "      <td>0.986095</td>\n",
       "      <td>384.698237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>constant</td>\n",
       "      <td>100000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>-0.013875</td>\n",
       "      <td>-0.092863</td>\n",
       "      <td>0.985746</td>\n",
       "      <td>201.032899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>constant</td>\n",
       "      <td>100000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.003820</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>-0.015644</td>\n",
       "      <td>-0.100297</td>\n",
       "      <td>0.983934</td>\n",
       "      <td>245.464295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>constant</td>\n",
       "      <td>100000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>0.006954</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>-0.019607</td>\n",
       "      <td>-0.110386</td>\n",
       "      <td>0.979860</td>\n",
       "      <td>246.552158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             param_learning_rate param_max_iter    param_loss param_eta0  \\\n",
       "rank_test_R2                                                               \n",
       "2                     invscaling         100000  squared_loss        0.1   \n",
       "1                     invscaling         100000  squared_loss       0.05   \n",
       "3                     invscaling         100000  squared_loss       0.01   \n",
       "4                       constant         100000  squared_loss       0.01   \n",
       "5                       constant         100000  squared_loss       0.05   \n",
       "6                       constant         100000  squared_loss        0.1   \n",
       "\n",
       "             param_penalty  rank_test_-MSE  rank_test_-MAE  std_test_-MSE  \\\n",
       "rank_test_R2                                                                \n",
       "2                     None               2               1       0.000498   \n",
       "1                     None               1               2       0.000486   \n",
       "3                     None               3               3       0.000495   \n",
       "4                     None               4               4       0.000426   \n",
       "5                     None               5               5       0.001080   \n",
       "6                     None               6               6       0.002519   \n",
       "\n",
       "              std_test_-MAE  std_test_R2  mean_test_-MSE  mean_test_-MAE  \\\n",
       "rank_test_R2                                                               \n",
       "2                  0.001501     0.000566       -0.013370       -0.090977   \n",
       "1                  0.001478     0.000552       -0.013347       -0.091028   \n",
       "3                  0.001430     0.000562       -0.013534       -0.091610   \n",
       "4                  0.000921     0.000461       -0.013875       -0.092863   \n",
       "5                  0.003820     0.001057       -0.015644       -0.100297   \n",
       "6                  0.006954     0.002564       -0.019607       -0.110386   \n",
       "\n",
       "              mean_test_R2  mean_fit_time  \n",
       "rank_test_R2                               \n",
       "2                 0.986263     409.906274  \n",
       "1                 0.986287     409.800223  \n",
       "3                 0.986095     384.698237  \n",
       "4                 0.985746     201.032899  \n",
       "5                 0.983934     245.464295  \n",
       "6                 0.979860     246.552158  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10.sort_values(['rank_test_-MAE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_eta0</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>rank_test_-MSE</th>\n",
       "      <th>rank_test_-MAE</th>\n",
       "      <th>std_test_-MSE</th>\n",
       "      <th>std_test_-MAE</th>\n",
       "      <th>std_test_R2</th>\n",
       "      <th>mean_test_-MSE</th>\n",
       "      <th>mean_test_-MAE</th>\n",
       "      <th>mean_test_R2</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_R2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>100000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>-0.013347</td>\n",
       "      <td>-0.091028</td>\n",
       "      <td>0.986287</td>\n",
       "      <td>409.800223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>100000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>-0.013370</td>\n",
       "      <td>-0.090977</td>\n",
       "      <td>0.986263</td>\n",
       "      <td>409.906274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>100000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>-0.013534</td>\n",
       "      <td>-0.091610</td>\n",
       "      <td>0.986095</td>\n",
       "      <td>384.698237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>constant</td>\n",
       "      <td>100000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>-0.013875</td>\n",
       "      <td>-0.092863</td>\n",
       "      <td>0.985746</td>\n",
       "      <td>201.032899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>constant</td>\n",
       "      <td>100000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.003820</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>-0.015644</td>\n",
       "      <td>-0.100297</td>\n",
       "      <td>0.983934</td>\n",
       "      <td>245.464295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>constant</td>\n",
       "      <td>100000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>0.006954</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>-0.019607</td>\n",
       "      <td>-0.110386</td>\n",
       "      <td>0.979860</td>\n",
       "      <td>246.552158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             param_learning_rate param_max_iter    param_loss param_eta0  \\\n",
       "rank_test_R2                                                               \n",
       "1                     invscaling         100000  squared_loss       0.05   \n",
       "2                     invscaling         100000  squared_loss        0.1   \n",
       "3                     invscaling         100000  squared_loss       0.01   \n",
       "4                       constant         100000  squared_loss       0.01   \n",
       "5                       constant         100000  squared_loss       0.05   \n",
       "6                       constant         100000  squared_loss        0.1   \n",
       "\n",
       "             param_penalty  rank_test_-MSE  rank_test_-MAE  std_test_-MSE  \\\n",
       "rank_test_R2                                                                \n",
       "1                     None               1               2       0.000486   \n",
       "2                     None               2               1       0.000498   \n",
       "3                     None               3               3       0.000495   \n",
       "4                     None               4               4       0.000426   \n",
       "5                     None               5               5       0.001080   \n",
       "6                     None               6               6       0.002519   \n",
       "\n",
       "              std_test_-MAE  std_test_R2  mean_test_-MSE  mean_test_-MAE  \\\n",
       "rank_test_R2                                                               \n",
       "1                  0.001478     0.000552       -0.013347       -0.091028   \n",
       "2                  0.001501     0.000566       -0.013370       -0.090977   \n",
       "3                  0.001430     0.000562       -0.013534       -0.091610   \n",
       "4                  0.000921     0.000461       -0.013875       -0.092863   \n",
       "5                  0.003820     0.001057       -0.015644       -0.100297   \n",
       "6                  0.006954     0.002564       -0.019607       -0.110386   \n",
       "\n",
       "              mean_test_R2  mean_fit_time  \n",
       "rank_test_R2                               \n",
       "1                 0.986287     409.800223  \n",
       "2                 0.986263     409.906274  \n",
       "3                 0.986095     384.698237  \n",
       "4                 0.985746     201.032899  \n",
       "5                 0.983934     245.464295  \n",
       "6                 0.979860     246.552158  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10.sort_values(['rank_test_-MSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refining the search\n",
    "   - Given the above rank we are selecting the 3 top configurations and re-running the grid with more iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 63.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "       loss='squared_loss', max_iter=None, n_iter=None, penalty=None,\n",
       "       power_t=0.25, random_state=None, shuffle=True, tol=None,\n",
       "       verbose=False, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_iter': [500000], 'eta0': [0.1, 0.05, 0.01], 'loss': ['squared_loss'], 'penalty': [None], 'learning_rate': ['invscaling']},\n",
       "       pre_dispatch='2*n_jobs', refit='R2', return_train_score='warn',\n",
       "       scoring={'-MSE': 'neg_mean_squared_error', '-MAE': 'neg_mean_absolute_error', 'R2': 'r2'},\n",
       "       verbose=True)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {}\n",
    "regr = experiments.get_sklearn_sgd(params)\n",
    "regr.verbose = False\n",
    "params = {\n",
    "    'learning_rate':['invscaling'],\n",
    "    'eta0': [0.1, 0.05, 0.01], # since 0.01 had a good result in the previous results \n",
    "    'penalty': [None], # Those penalties are easier to implement if needed\n",
    "    'loss': ['squared_loss'], # Since we are running the MSE loss function for the Custom Implementing\n",
    "    'max_iter':[500000] # Fixed the number of iterations to avoid the long time executions\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "        '-MSE': 'neg_mean_squared_error',\n",
    "        '-MAE': 'neg_mean_absolute_error',\n",
    "        'R2': 'r2'\n",
    "    }\n",
    "\n",
    "# We are using R2 to refit because it gave a better view of the results above when compared with the MSE and MAE\n",
    "regr = GridSearchCV(regr, params, cv=5, scoring=scoring, refit='R2', n_jobs=-1, verbose=True)\n",
    "regr.fit(X_train, np.log(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_eta0</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>rank_test_-MSE</th>\n",
       "      <th>rank_test_-MAE</th>\n",
       "      <th>std_test_-MSE</th>\n",
       "      <th>std_test_-MAE</th>\n",
       "      <th>std_test_R2</th>\n",
       "      <th>mean_test_-MSE</th>\n",
       "      <th>mean_test_-MAE</th>\n",
       "      <th>mean_test_R2</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_R2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>500000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>-0.013346</td>\n",
       "      <td>-0.091035</td>\n",
       "      <td>0.986288</td>\n",
       "      <td>1914.672608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>500000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>-0.013347</td>\n",
       "      <td>-0.091010</td>\n",
       "      <td>0.986287</td>\n",
       "      <td>1760.760698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>500000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>-0.013364</td>\n",
       "      <td>-0.091116</td>\n",
       "      <td>0.986269</td>\n",
       "      <td>1979.661419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             param_learning_rate param_max_iter    param_loss param_eta0  \\\n",
       "rank_test_R2                                                               \n",
       "1                     invscaling         500000  squared_loss       0.05   \n",
       "2                     invscaling         500000  squared_loss       0.01   \n",
       "3                     invscaling         500000  squared_loss        0.1   \n",
       "\n",
       "             param_penalty  rank_test_-MSE  rank_test_-MAE  std_test_-MSE  \\\n",
       "rank_test_R2                                                                \n",
       "1                     None               1               2       0.000482   \n",
       "2                     None               2               1       0.000485   \n",
       "3                     None               3               3       0.000476   \n",
       "\n",
       "              std_test_-MAE  std_test_R2  mean_test_-MSE  mean_test_-MAE  \\\n",
       "rank_test_R2                                                               \n",
       "1                  0.001459     0.000549       -0.013346       -0.091035   \n",
       "2                  0.001484     0.000553       -0.013347       -0.091010   \n",
       "3                  0.001433     0.000546       -0.013364       -0.091116   \n",
       "\n",
       "              mean_test_R2  mean_fit_time  \n",
       "rank_test_R2                               \n",
       "1                 0.986288    1914.672608  \n",
       "2                 0.986287    1760.760698  \n",
       "3                 0.986269    1979.661419  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "\n",
    "columns = [\n",
    "'param_learning_rate',\n",
    "'param_max_iter',\n",
    "'param_loss',\n",
    "'param_eta0',\n",
    "'param_penalty',\n",
    "'rank_test_-MSE',\n",
    "'rank_test_-MAE',\n",
    "'rank_test_R2',\n",
    "'std_test_-MSE',\n",
    "'std_test_-MAE',\n",
    "'std_test_R2',\n",
    "'mean_test_-MSE',\n",
    "'mean_test_-MAE',\n",
    "'mean_test_R2', \n",
    "'mean_fit_time']\n",
    "\n",
    "results = pd.DataFrame(regr.cv_results_)\n",
    "top10 = results[columns].sort_values(by=['rank_test_R2', 'mean_test_R2']).head(10).copy()\n",
    "top10.sort_values(by=['rank_test_R2', 'mean_test_R2'])\n",
    "top10.set_index('rank_test_R2', inplace=True, drop=True)\n",
    "top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2f4185bd30>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEHCAYAAABIsPrhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAFF9JREFUeJzt3X/wXXV95/Hnq4CsW6vg8t1MTEJDneAOoBshg+y6OuxSIVBrsNulMB0J6BodYaptnS60f4B2mLFbLVO2LjQuWWCKUCoi2RWLKWN13N0oXzBN+FkCwpBMhK9iQYtDG3jvH/d8yyV+v8n9fu/N9wY+z8fMne857/M553wul8nrns85555UFZKkNv3MuDsgSRofQ0CSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1zBCQpIYZApLUsIPH3YF9OeKII2r58uXj7oYkvWzcdddd36+qiUHaHvAhsHz5ciYnJ8fdDUl62Ujy2KBtHQ6SpIYZApLUMENAkhq2zxBIsizJ15Lcl+TeJB/t6q9PsinJQ93fw7t6klyRZHuSrUmO79vW2q79Q0nW7r+3JUkaxCBHAruB366qY4CTgAuSHANcBNxRVSuAO7p5gNOBFd1rHXAl9EIDuAR4G3AicMl0cEiSxmOfIVBVu6rq7m76R8D9wBJgDXBt1+xa4Mxueg1wXfVsBg5Lshg4DdhUVU9V1Q+BTcDqkb4bSdKczOmcQJLlwFuBbwGLqmpXt+h7wKJuegnweN9qO7rabPWZ9rMuyWSSyampqbl0UZI0BwOHQJLXADcDH6uqZ/qXVe8ZlSN7TmVVra+qVVW1amJioPsdJEnzMNDNYkkOoRcA11fVF7vyE0kWV9Wubrjnya6+E1jWt/rSrrYTOHmP+l/Pv+uSXknefO2bx92F/Wbb2m3j7sKsBrk6KMDVwP1V9Ud9izYC01f4rAVu7auf210ldBLwdDdsdDtwapLDuxPCp3Y1SdKYDHIk8HbgfcC2JFu62u8CnwJuSvIB4DHgrG7ZbcAZwHbgWeB8gKp6KsnvA3d27T5ZVU+N5F1IkuZlnyFQVd8EMsviU2ZoX8AFs2xrA7BhLh2UJO0/3jEsSQ0zBCSpYYaAJDXsgH+ewEJaftGXx92F/erRT/3SuLsg6QDjkYAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDBnnG8IYkTya5p6/250m2dK9Hpx87mWR5kp/0Lbuqb50TkmxLsj3JFd2ziyVJYzTIT0lfA/wJcN10oap+bXo6yWeAp/vaP1xVK2fYzpXAB4Fv0XsO8WrgK3PvsiRpVAZ5xvA3kiyfaVn3bf4s4D/sbRtJFgOvrarN3fx1wJkYAhqlS1837h7sX5c+ve820hwNe07gHcATVfVQX+2oJN9J8vUk7+hqS4AdfW12dLUZJVmXZDLJ5NTU1JBdlCTNZtgQOAe4oW9+F3BkVb0V+C3g80leO9eNVtX6qlpVVasmJiaG7KIkaTbzfrxkkoOBXwFOmK5V1XPAc930XUkeBo4GdgJL+1Zf2tUkSWM0zJHALwIPVNU/DfMkmUhyUDf9C8AK4JGq2gU8k+Sk7jzCucCtQ+xbkjQCg1wiegPw/4A3JdmR5APdorN56VAQwDuBrd0lo18APlxVT3XLPgL8D2A78DCeFJaksRvk6qBzZqmfN0PtZuDmWdpPAsfNsX+SpP3IO4YlqWGGgCQ1zBCQpIYZApLUMENAkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYM8XnJDkieT3NNXuzTJziRbutcZfcsuTrI9yYNJTuurr+5q25NcNPq3Ikmaq0GOBK4BVs9Qv7yqVnav2wCSHEPv2cPHduv89yQHdQ+f/yxwOnAMcE7XVpI0RoM8Y/gbSZYPuL01wI1V9Rzw3STbgRO7Zdur6hGAJDd2be+bc48lSSMzzDmBC5Ns7YaLDu9qS4DH+9rs6Gqz1SVJYzTfELgSeCOwEtgFfGZkPQKSrEsymWRyampqlJuWJPWZVwhU1RNV9XxVvQB8jheHfHYCy/qaLu1qs9Vn2/76qlpVVasmJibm00VJ0gDmFQJJFvfNvheYvnJoI3B2kkOTHAWsAL4N3AmsSHJUklfRO3m8cf7dliSNwj5PDCe5ATgZOCLJDuAS4OQkK4ECHgU+BFBV9ya5id4J393ABVX1fLedC4HbgYOADVV178jfjSRpTga5OuicGcpX76X9ZcBlM9RvA26bU+8kSfuVdwxLUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1zBCQpIYZApLUMENAkhpmCEhSw/YZAkk2JHkyyT19tT9M8kCSrUluSXJYV1+e5CdJtnSvq/rWOSHJtiTbk1yRJPvnLUmSBjXIkcA1wOo9apuA46rqLcDfAhf3LXu4qlZ2rw/31a8EPkjv4fMrZtimJGmB7TMEquobwFN71L5aVbu72c3A0r1tI8li4LVVtbmqCrgOOHN+XZYkjcoozgm8H/hK3/xRSb6T5OtJ3tHVlgA7+trs6GqSpDE6eJiVk/wesBu4vivtAo6sqh8kOQH4UpJj57HddcA6gCOPPHKYLkqS9mLeRwJJzgPeDfx6N8RDVT1XVT/opu8CHgaOBnby0iGjpV1tRlW1vqpWVdWqiYmJ+XZRkrQP8wqBJKuB3wHeU1XP9tUnkhzUTf8CvRPAj1TVLuCZJCd1VwWdC9w6dO8lSUPZ53BQkhuAk4EjkuwALqF3NdChwKbuSs/N3ZVA7wQ+meQfgReAD1fV9Enlj9C70ujV9M4h9J9HkCSNwT5DoKrOmaF89SxtbwZunmXZJHDcnHonSdqvvGNYkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDBgqBJBuSPJnknr7a65NsSvJQ9/fwrp4kVyTZnmRrkuP71lnbtX8oydrRvx1J0lwMeiRwDbB6j9pFwB1VtQK4o5sHOB1Y0b3WAVdCLzToPaT+bcCJwCXTwSFJGo+BQqCqvgE8tUd5DXBtN30tcGZf/brq2QwclmQxcBqwqaqeqqofApv46WCRJC2gYc4JLKqqXd3094BF3fQS4PG+dju62mz1n5JkXZLJJJNTU1NDdFGStDcjOTFcVQXUKLbVbW99Va2qqlUTExOj2qwkaQ/DhMAT3TAP3d8nu/pOYFlfu6Vdbba6JGlMhgmBjcD0FT5rgVv76ud2VwmdBDzdDRvdDpya5PDuhPCpXU2SNCYHD9IoyQ3AycARSXbQu8rnU8BNST4APAac1TW/DTgD2A48C5wPUFVPJfl94M6u3Seras+TzZKkBTRQCFTVObMsOmWGtgVcMMt2NgAbBu6dJGm/8o5hSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDDAFJati8QyDJm5Js6Xs9k+RjSS5NsrOvfkbfOhcn2Z7kwSSnjeYtSJLma6DHS86kqh4EVgIkOQjYCdxC75nCl1fVp/vbJzkGOBs4FngD8FdJjq6q5+fbB0nScEY1HHQK8HBVPbaXNmuAG6vquar6Lr0H0Z84ov1LkuZhVCFwNnBD3/yFSbYm2ZDk8K62BHi8r82OrvZTkqxLMplkcmpqakRdlCTtaegQSPIq4D3AX3SlK4E30hsq2gV8Zq7brKr1VbWqqlZNTEwM20VJ0ixGcSRwOnB3VT0BUFVPVNXzVfUC8DleHPLZCSzrW29pV5MkjckoQuAc+oaCkizuW/Ze4J5ueiNwdpJDkxwFrAC+PYL9S5Lmad5XBwEk+VngXcCH+sr/NclKoIBHp5dV1b1JbgLuA3YDF3hlkCSN11AhUFV/D/yLPWrv20v7y4DLhtmnJGl0vGNYkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGjZ0CCR5NMm2JFuSTHa11yfZlOSh7u/hXT1JrkiyPcnWJMcPu39J0vyN6kjg31fVyqpa1c1fBNxRVSuAO7p5gNPpPWB+BbAOuHJE+5ckzcP+Gg5aA1zbTV8LnNlXv656NgOHJVm8n/ogSdqHUYRAAV9NcleSdV1tUVXt6qa/ByzqppcAj/etu6OrvUSSdUkmk0xOTU2NoIuSpJkcPIJt/Luq2pnkXwKbkjzQv7CqKknNZYNVtR5YD7Bq1ao5rStJGtzQRwJVtbP7+yRwC3Ai8MT0ME/398mu+U5gWd/qS7uaJGkMhgqBJD+b5Oemp4FTgXuAjcDartla4NZueiNwbneV0EnA033DRpKkBTbscNAi4JYk09v6fFX9ZZI7gZuSfAB4DDira38bcAawHXgWOH/I/UuShjBUCFTVI8C/nqH+A+CUGeoFXDDMPiVJo+Mdw5LUMENAkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktSweYdAkmVJvpbkviT3JvloV780yc4kW7rXGX3rXJxke5IHk5w2ijcgSZq/YR4vuRv47aq6u3vY/F1JNnXLLq+qT/c3TnIMcDZwLPAG4K+SHF1Vzw/RB0nSEOZ9JFBVu6rq7m76R8D9wJK9rLIGuLGqnquq79J72PyJ892/JGl4IzknkGQ58FbgW13pwiRbk2xIcnhXWwI83rfaDmYJjSTrkkwmmZyamhpFFyVJMxg6BJK8BrgZ+FhVPQNcCbwRWAnsAj4z121W1fqqWlVVqyYmJobtoiRpFkOFQJJD6AXA9VX1RYCqeqKqnq+qF4DP8eKQz05gWd/qS7uaJGlMhrk6KMDVwP1V9Ud99cV9zd4L3NNNbwTOTnJokqOAFcC357t/SdLwhrk66O3A+4BtSbZ0td8FzkmyEijgUeBDAFV1b5KbgPvoXVl0gVcGSdJ4zTsEquqbQGZYdNte1rkMuGy++5QkjZZ3DEtSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDFjwEkqxO8mCS7UkuWuj9S5JetKAhkOQg4LPA6cAx9J5HfMxC9kGS9KKFPhI4EdheVY9U1T8ANwJrFrgPkqTOQofAEuDxvvkdXU2SNAYHj7sDM0myDljXzf44yYPj7M9+dATw/YXaWf5gofbUjAX9/PhEFmxXjViwzy/nLfhn9/ODNlzoENgJLOubX9rVXqKq1gPrF6pT45JksqpWjbsfmh8/v5c3P7+ehR4OuhNYkeSoJK8CzgY2LnAfJEmdBT0SqKrdSS4EbgcOAjZU1b0L2QdJ0osW/JxAVd0G3LbQ+z1AveKHvF7h/Pxe3vz8gFTVuPsgSRoTfzZCkhpmCEhSww7I+wQkaZSSnAhUVd3Z/VTNauCB7hxl0zwnIA0oyb+id4f7t6rqx3311VX1l+PrmfYmySX0fq/sYGAT8Dbga8C7gNur6rIxdm/sDIEDRJLzq+p/jrsfmlmS3wAuAO4HVgIfrapbu2V3V9Xx4+yfZpdkG73P7FDge8DSqnomyavpBfpbxtrBMXM46MDxCcAQOHB9EDihqn6cZDnwhSTLq+qPAX/P4cC2u6qeB55N8nBVPQNQVT9J8sKY+zZ2hsACSrJ1tkXAooXsi+bsZ6aHgKrq0SQn0wuCn8cQOND9Q5J/XlXPAidMF5O8DjAExt2BxiwCTgN+uEc9wP9d+O5oDp5IsrKqtgB0RwTvBjYAbx5v17QP76yq5wCqqv8f/UOAtePp0oHDEFhY/xt4zfQ/JP2S/PXCd0dzcC6wu79QVbuBc5P86Xi6pEFMB8AM9e+zkL8Ce4DyxLAkNcybxSSpYYaAJDXMEFCzklya5OMDtj0vyRvmuZ+Tk/zbAfqyM8mWJPclOadv2R8meSDJ1iS3JDlsPv2QZmII6BUhPfvz/+fzgHmFAHAysNcQ6FxeVSuBNcCfJjmkq28Cjutuavpb4OJ59kP6KYaAXraSLE/yYJLrgHuAq5NMJrk3ySf62j2a5BNJ7k6yrfv5hz239cEkX+nuIt1z2a8Cq4Dru2/qr05yQpKvJ7krye1JFndtf6P7Jr81yY3djWUfBn6zW/cd+3pfVfUQ8CxweDf/1e5KJIDN9B7LKo2El4jq5W4FsLaqNid5fVU9leQg4I4kb6mq6Rv0vl9Vxyf5CPBx4D9Pb6B72t27gDNnupywqr7Qtfl4VU1239D/G7CmqqaS/BpwGfB+4CLgqKp6LslhVfV3Sa4CflxVnx7kDSU5Hnioqp6cYfH7gT8f7D+NtG+GgF7uHquqzd30WUnW0fv/ejFwDDAdAl/s/t4F/Erf+ucCj9MLgH8ccJ9vAo4DNiWB3qNSd3XLttI7YvgS8KU5vpffTHI+cDTwy3suTPJ79O5VuH6O25Vm5XCQXu7+HiDJUfS+4Z/SjZ1/Gfhnfe2mv+E/z0u//GwDljO3IZYA91bVyu715qo6tVv2S8BngeOBO5PM5YvW5VV1LPAf6Q1t/VP/k5wHvBv49fLmHo2QIaBXitfSC4Snkyyi99PBg/gO8CFg4z6u/vkR8HPd9IPARJJ/A5DkkCTHdieml1XV14D/ArwOeM0e6+5TVW0EJul+0iDJauB3gPd0v38jjYwhoFeEqvobev+gPwB8Hvg/c1j3m/SOIr6c5IhZml0DXJVkC73hn18F/iDJ3wBb6F39cxDwZ91PF38HuKKq/g74X8B7Bz0x3Pkk8FtdsPwJvRDZ1G3jqkHfm7Qv/myEJDXMIwFJaphXB0l9knwWePse5T8e1VPfuit8/tMe5b9o/RGHGh+HgySpYQ4HSVLDDAFJapghIEkNMwQkqWGGgCQ17P8D0ci+29RD3coAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "top10.mean_fit_time.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2f418239e8>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,5))\n",
    "top10.mean_test_R2.plot.bar(yerr=top10.std_test_R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2f417d9a58>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "top10.std_test_R2.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_eta0</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>rank_test_-MSE</th>\n",
       "      <th>rank_test_-MAE</th>\n",
       "      <th>std_test_-MSE</th>\n",
       "      <th>std_test_-MAE</th>\n",
       "      <th>std_test_R2</th>\n",
       "      <th>mean_test_-MSE</th>\n",
       "      <th>mean_test_-MAE</th>\n",
       "      <th>mean_test_R2</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_R2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>500000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>-0.013346</td>\n",
       "      <td>-0.091035</td>\n",
       "      <td>0.986288</td>\n",
       "      <td>1914.672608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>500000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>-0.013347</td>\n",
       "      <td>-0.091010</td>\n",
       "      <td>0.986287</td>\n",
       "      <td>1760.760698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>500000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>-0.013364</td>\n",
       "      <td>-0.091116</td>\n",
       "      <td>0.986269</td>\n",
       "      <td>1979.661419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             param_learning_rate param_max_iter    param_loss param_eta0  \\\n",
       "rank_test_R2                                                               \n",
       "1                     invscaling         500000  squared_loss       0.05   \n",
       "2                     invscaling         500000  squared_loss       0.01   \n",
       "3                     invscaling         500000  squared_loss        0.1   \n",
       "\n",
       "             param_penalty  rank_test_-MSE  rank_test_-MAE  std_test_-MSE  \\\n",
       "rank_test_R2                                                                \n",
       "1                     None               1               2       0.000482   \n",
       "2                     None               2               1       0.000485   \n",
       "3                     None               3               3       0.000476   \n",
       "\n",
       "              std_test_-MAE  std_test_R2  mean_test_-MSE  mean_test_-MAE  \\\n",
       "rank_test_R2                                                               \n",
       "1                  0.001459     0.000549       -0.013346       -0.091035   \n",
       "2                  0.001484     0.000553       -0.013347       -0.091010   \n",
       "3                  0.001433     0.000546       -0.013364       -0.091116   \n",
       "\n",
       "              mean_test_R2  mean_fit_time  \n",
       "rank_test_R2                               \n",
       "1                 0.986288    1914.672608  \n",
       "2                 0.986287    1760.760698  \n",
       "3                 0.986269    1979.661419  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10.sort_values(['rank_test_R2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_eta0</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>rank_test_-MSE</th>\n",
       "      <th>rank_test_-MAE</th>\n",
       "      <th>std_test_-MSE</th>\n",
       "      <th>std_test_-MAE</th>\n",
       "      <th>std_test_R2</th>\n",
       "      <th>mean_test_-MSE</th>\n",
       "      <th>mean_test_-MAE</th>\n",
       "      <th>mean_test_R2</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_R2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>500000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>-0.013347</td>\n",
       "      <td>-0.091010</td>\n",
       "      <td>0.986287</td>\n",
       "      <td>1760.760698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>500000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>-0.013346</td>\n",
       "      <td>-0.091035</td>\n",
       "      <td>0.986288</td>\n",
       "      <td>1914.672608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>500000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>-0.013364</td>\n",
       "      <td>-0.091116</td>\n",
       "      <td>0.986269</td>\n",
       "      <td>1979.661419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             param_learning_rate param_max_iter    param_loss param_eta0  \\\n",
       "rank_test_R2                                                               \n",
       "2                     invscaling         500000  squared_loss       0.01   \n",
       "1                     invscaling         500000  squared_loss       0.05   \n",
       "3                     invscaling         500000  squared_loss        0.1   \n",
       "\n",
       "             param_penalty  rank_test_-MSE  rank_test_-MAE  std_test_-MSE  \\\n",
       "rank_test_R2                                                                \n",
       "2                     None               2               1       0.000485   \n",
       "1                     None               1               2       0.000482   \n",
       "3                     None               3               3       0.000476   \n",
       "\n",
       "              std_test_-MAE  std_test_R2  mean_test_-MSE  mean_test_-MAE  \\\n",
       "rank_test_R2                                                               \n",
       "2                  0.001484     0.000553       -0.013347       -0.091010   \n",
       "1                  0.001459     0.000549       -0.013346       -0.091035   \n",
       "3                  0.001433     0.000546       -0.013364       -0.091116   \n",
       "\n",
       "              mean_test_R2  mean_fit_time  \n",
       "rank_test_R2                               \n",
       "2                 0.986287    1760.760698  \n",
       "1                 0.986288    1914.672608  \n",
       "3                 0.986269    1979.661419  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10.sort_values(['rank_test_-MAE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_eta0</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>rank_test_-MSE</th>\n",
       "      <th>rank_test_-MAE</th>\n",
       "      <th>std_test_-MSE</th>\n",
       "      <th>std_test_-MAE</th>\n",
       "      <th>std_test_R2</th>\n",
       "      <th>mean_test_-MSE</th>\n",
       "      <th>mean_test_-MAE</th>\n",
       "      <th>mean_test_R2</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_R2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>500000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>-0.013346</td>\n",
       "      <td>-0.091035</td>\n",
       "      <td>0.986288</td>\n",
       "      <td>1914.672608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>500000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>-0.013347</td>\n",
       "      <td>-0.091010</td>\n",
       "      <td>0.986287</td>\n",
       "      <td>1760.760698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>invscaling</td>\n",
       "      <td>500000</td>\n",
       "      <td>squared_loss</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>-0.013364</td>\n",
       "      <td>-0.091116</td>\n",
       "      <td>0.986269</td>\n",
       "      <td>1979.661419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             param_learning_rate param_max_iter    param_loss param_eta0  \\\n",
       "rank_test_R2                                                               \n",
       "1                     invscaling         500000  squared_loss       0.05   \n",
       "2                     invscaling         500000  squared_loss       0.01   \n",
       "3                     invscaling         500000  squared_loss        0.1   \n",
       "\n",
       "             param_penalty  rank_test_-MSE  rank_test_-MAE  std_test_-MSE  \\\n",
       "rank_test_R2                                                                \n",
       "1                     None               1               2       0.000482   \n",
       "2                     None               2               1       0.000485   \n",
       "3                     None               3               3       0.000476   \n",
       "\n",
       "              std_test_-MAE  std_test_R2  mean_test_-MSE  mean_test_-MAE  \\\n",
       "rank_test_R2                                                               \n",
       "1                  0.001459     0.000549       -0.013346       -0.091035   \n",
       "2                  0.001484     0.000553       -0.013347       -0.091010   \n",
       "3                  0.001433     0.000546       -0.013364       -0.091116   \n",
       "\n",
       "              mean_test_R2  mean_fit_time  \n",
       "rank_test_R2                               \n",
       "1                 0.986288    1914.672608  \n",
       "2                 0.986287    1760.760698  \n",
       "3                 0.986269    1979.661419  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10.sort_values(['rank_test_-MSE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best parameters found "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eta0': 0.05,\n",
       " 'learning_rate': 'invscaling',\n",
       " 'loss': 'squared_loss',\n",
       " 'max_iter': 500000,\n",
       " 'penalty': None}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
